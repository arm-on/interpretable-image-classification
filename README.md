Interpretability methods applied on image classifiers trained on MNIST and CIFAR10
---
This repo includes the files (jupyter notebooks) for the interpretation of two deep neural networks capable of classifying 0-9 digits based on the images belonging to the MNIST dataset, and ten categories (including "airplane", "automobile", "bird", "cat", "deer", "dog", "frog", "horse", "ship", and "truck") of the CIFAR10 dataset. 

The project includes some phases:
- Training neural networks on the datasets
- Implementing interpretability methods
- Comparing methods based on visualization
- Comparing methods based on the models
- Interpretability in Bayesian Neural Networks
